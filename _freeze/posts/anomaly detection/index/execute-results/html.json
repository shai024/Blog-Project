{
  "hash": "774800d80b9fae1b36dc0ffe775e0d8b",
  "result": {
    "markdown": "---\ntitle: \"Anomaly/Outlier Detection\"\nauthor: \"Britney Aiken\"\ndate: \"2023-12-04\"\nimage: \"anomaly.png\"\ncode-fold: true\ncode-tools: true\ncode-block-bg: true\ncode-block-border-left: \"#31BAE9\"\n---\n\n![Anomaly detection is useful in a wide variety of applications, such as fraud detection, detecting defective products, and cybersecurity.](anomaly.png)\n\n### What is Anomaly Detection?\nThe goal is to learn what “normal” data looks like, and then use that to detect abnormal instances. These instances are called anomalies or outliers. \n\n### Why is it important?\nAnomaly detection is a critical tool for maintaining the integrity and security of a system. It enables early identification of unusual patterns that may causes issues.\n\n\n### Algorithms for Anamoly Detction\n\n**Gaussian Mixture**\nAnomaly detection assumes that normal instances occur more often than outliers. The algorithm starts by learning the patterns of normal behavior and analzes the datapoint that do not fit the pattern. When using a Gaussian mixture model for anomaly detection, any instance located in a low-density region can be considered an anomaly.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.mixture import GaussianMixture\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.datasets import fetch_openml\n\ndataset = fetch_openml('S3', as_frame=False)\ndata = dataset.data[:800]\n\ngm = GaussianMixture().fit(data)\ndensities = gm.score_samples(data)\ndensity_threshold = np.percentile(densities, 2)\nanomalies = data[densities < density_threshold]\n\nplt.scatter(data[:, 0], data[:, 1])\nplt.scatter(anomalies[:, 0], anomalies[:, 1], color='r', marker='*')\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\britn\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n  warn(\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-2.png){}\n:::\n:::\n\n\nReferences: [@Fränti]\n\n**Fast-MCD (Minimum Covariance Determinant)**\nThis algorithm is useful for outlier detection, especially when trying to clean up a dataset. When the algorithm estimates the parameters of the Gaussian distribution, it ignores the instances that are most likely outlier, making it easier to identify them.\n\n**Isolation Forest**\nThis algorithm works well in high-dimensional datasets. It builds a random forest where each decision tree grows randomly. The datapoints gradually spread apart causing the anomalies to become isolated much fater than normal datapoints. \n\n**Local outlier factor (LOF)**\nThis algorithm compares the density of instances around a given instance to the density around its neighbors. An anomaly is often more isolated than its k-nearest neighbors.\n\n**One-class SVM**\nThis algorithm is works well for novelty detection. Novelty detection differs from anomaly detection by assuming the algorithm was trained on a “clean” dataset, with no outliers. One-class SVM works by finding a small region that encompasses all the instances. If a new instance does not fall within this region, it is an anomaly\n\n\n### References\nFränti , P, and O Virmajoki. “S3.” OpenML, openml.org/search?type=data&amp;status=active&amp;sort=qualities.NumberOfNumericFeatures&amp;id=42112. Accessed 15 Dec. 2023.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}